{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvPnsh+M5qo5c0tfaTORXw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tashir0605/Cocepts-And-Practice/blob/main/Deep_Learning/DataAugmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Augmentation – Summary**\n",
        "\n",
        "## **1. Concept**\n",
        "- **Purpose:** A technique to increase the amount and diversity of training data without actually collecting new samples.  \n",
        "- **Benefit:** Helps deep learning models perform better, especially when available data is limited.  \n",
        "- **Idea:** Create variations of existing data (e.g., flipping, rotating, adding noise) so the model learns to recognize patterns in different conditions.  \n",
        "- **Advanced Approach:** Adaptive augmentation changes transformations based on the model’s learning progress, making training more effective.  \n",
        "\n",
        "---\n",
        "\n",
        "## **2. Augmentation Techniques**\n",
        "\n",
        "### **A. Audio Data Augmentation**\n",
        "1. **Noise Injection** – Add Gaussian or random noise to make the model robust to background sounds.  \n",
        "2. **Shifting** – Shift the audio forward or backward by random time intervals.  \n",
        "3. **Speed Change** – Stretch or compress the audio timeline at a fixed rate.  \n",
        "4. **Pitch Change** – Randomly adjust the pitch of the audio.  \n",
        "\n",
        "### **B. Text Data Augmentation**\n",
        "1. **Word/Sentence Shuffling** – Randomly reorder words or sentences.  \n",
        "2. **Word Replacement** – Swap words with their synonyms.  \n",
        "3. **Syntax-Tree Manipulation** – Paraphrase while keeping the meaning intact.  \n",
        "4. **Random Word Insertion** – Add extra words in random positions.  \n",
        "5. **Random Word Deletion** – Remove words at random to encourage model robustness.  \n"
      ],
      "metadata": {
        "id": "kgJyv0E6Iz5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Augmentation in PyTorch: Cutout & Mixup**\n",
        "\n",
        "---\n",
        "\n",
        "## **1. Cutout Augmentation**\n",
        "\n",
        "**Concept:**  \n",
        "Cutout randomly masks out square regions of the input image, forcing the model to rely on less obvious parts of the object for classification.  \n",
        "This improves robustness by preventing over-reliance on specific features.\n",
        "\n",
        "---\n",
        "\n",
        "### **Code: Cutout with Albumentations**\n",
        "```python\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "# Define a transformation pipeline\n",
        "transforms_cutout = A.Compose([\n",
        "    A.Resize(256, 256),  # Resize all images to 256x256 pixels\n",
        "    A.CoarseDropout(\n",
        "        max_holes=1,        # Number of regions to cut out (1 in this example)\n",
        "        max_height=128,     # Max height of cutout region\n",
        "        max_width=128,      # Max width of cutout region\n",
        "        fill_value=0,       # Pixel value to fill the cutout region (black)\n",
        "        p=0.5               # Probability of applying Cutout to an image\n",
        "    ),\n",
        "    ToTensorV2(),          # Convert NumPy image to PyTorch tensor\n",
        "])\n"
      ],
      "metadata": {
        "id": "n2RxQXqfJ993"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Cutout Pipeline — Step-by-Step**\n",
        "\n",
        "1. **`A.Resize(256, 256)`** → Ensures all images are the same size.  \n",
        "2. **`A.CoarseDropout(...)`** → Randomly removes a square patch from the image.  \n",
        "   - **`fill_value=0`** → The removed patch is filled with black pixels.  \n",
        "   - **`p=0.5`** → Only half of the images will have a cutout applied.  \n",
        "3. **`ToTensorV2()`** → Converts the image to a **PyTorch tensor** (required for model input)."
      ],
      "metadata": {
        "id": "4I7jleV0KPmH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Mixup Augmentation**\n",
        "\n",
        "---\n",
        "\n",
        "## **Concept**\n",
        "Mixup creates new training samples by **blending two random images and their labels**.  \n",
        "This encourages the model to behave more **linearly between samples** and helps **prevent overfitting**.\n",
        "\n",
        "---\n",
        "\n",
        "## **Code: Mixup Implementation**\n",
        "```python\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "\n",
        "# Function to apply Mixup to a batch\n",
        "def mixup(data, targets, alpha):\n",
        "    indices = torch.randperm(data.size(0))   # Randomly shuffle the batch\n",
        "    shuffled_data = data[indices]            # Get shuffled images\n",
        "    shuffled_targets = targets[indices]      # Get shuffled labels\n",
        "\n",
        "    lam = np.random.beta(alpha, alpha)       # Mixing factor from Beta distribution\n",
        "    new_data = data * lam + shuffled_data * (1 - lam)  # Blend images\n",
        "    new_targets = [targets, shuffled_targets, lam]     # Store both sets of labels and lam\n",
        "    return new_data, new_targets\n",
        "\n",
        "# Custom loss function for Mixup\n",
        "def mixup_criterion(preds, targets):\n",
        "    targets1, targets2, lam = targets\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    return lam * criterion(preds, targets1) + (1 - lam) * criterion(preds, targets2)\n"
      ],
      "metadata": {
        "id": "ZJteZwNaKzmY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step-by-step Explanation (Mixup Function)**\n",
        "\n",
        "1. **`torch.randperm(data.size(0))`** → Creates a random permutation of the batch indices.  \n",
        "2. **`shuffled_data` / `shuffled_targets`** → The original batch reordered randomly using those indices.  \n",
        "3. **`lam`** → A random blending factor sampled from a **Beta** distribution (`np.random.beta(alpha, alpha)`).  \n",
        "4. **`new_data`** → Weighted combination of original and shuffled images: `data * lam + shuffled_data * (1 - lam)`.  \n",
        "5. **`new_targets`** → A container holding both label sets and the mixing weight: `[targets, shuffled_targets, lam]`.  \n",
        "6. **`mixup_criterion`** → Computes the weighted loss for both labels:  \n",
        "   `lam * CE(preds, targets1) + (1 - lam) * CE(preds, targets2)`.\n"
      ],
      "metadata": {
        "id": "BiakVQbFK2_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Mixup in the Training Loop**\n"
      ],
      "metadata": {
        "id": "xpcBKEuzLPUY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IX1CT37NIJB3"
      },
      "outputs": [],
      "source": [
        "p_mixup = 0.5  # Probability of applying Mixup\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    for samples, labels in train_dataloader:\n",
        "        samples, labels = samples.to(device), labels.to(device)\n",
        "\n",
        "        samples = samples / 255  # Normalize pixel values (0-255 → 0-1)\n",
        "\n",
        "        # Decide whether to apply Mixup\n",
        "        p = np.random.rand()\n",
        "        if p < p_mixup:\n",
        "            samples, labels = mixup(samples, labels, alpha=0.8)\n",
        "\n",
        "        optimizer.zero_grad()  # Reset gradients\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(samples)\n",
        "\n",
        "        # Compute loss (with Mixup or normal)\n",
        "        if p < p_mixup:\n",
        "            loss = mixup_criterion(output, labels)\n",
        "        else:\n",
        "            loss = nn.CrossEntropyLoss()(output, labels)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step-by-step Explanation (Training Loop)**\n",
        "\n",
        "1. **`p_mixup`** → Sets the probability of applying Mixup augmentation (e.g., 0.5 = 50% of batches).  \n",
        "2. **Normalize images** → Scales pixel values from `[0, 255]` to `[0, 1]` for better training stability.  \n",
        "3. **Mixup decision** → Randomly decide for each batch whether Mixup should be applied.  \n",
        "4. **Forward pass** → Feed the batch through the model to get predictions (`output = model(samples)`).  \n",
        "5. **Loss calculation** →  \n",
        "   - **If Mixup applied** → Use `mixup_criterion` to compute the weighted loss for both label sets.  \n",
        "   - **If Mixup not applied** → Use the standard `CrossEntropyLoss`.  \n",
        "6. **Backpropagation & optimizer step** → Compute gradients with `.backward()` and update model weights using `optimizer.step()`.  \n"
      ],
      "metadata": {
        "id": "M3dInpYgLmQs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CutMix Augmentation**\n",
        "\n",
        "---\n",
        "\n",
        "## **Concept**\n",
        "CutMix is similar to Mixup, but instead of blending entire images,  \n",
        "it **cuts a rectangular patch from one image** and pastes it into another,  \n",
        "adjusting the labels according to the area replaced.  \n",
        "This helps the model learn from **local features** as well as global context.\n",
        "\n",
        "---\n",
        "\n",
        "## **Code: CutMix Implementation**\n",
        "```python\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Function to apply CutMix to a batch\n",
        "def cutmix(data, targets, alpha):\n",
        "    # Shuffle the batch\n",
        "    indices = torch.randperm(data.size(0))\n",
        "    shuffled_data = data[indices]\n",
        "    shuffled_targets = targets[indices]\n",
        "\n",
        "    # Mixing factor\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "\n",
        "    # Get bounding box coordinates for the cut\n",
        "    bbx1, bby1, bbx2, bby2 = rand_bbox(data.size(), lam)\n",
        "\n",
        "    # Replace the patch in original images with the patch from shuffled images\n",
        "    data[:, :, bbx1:bbx2, bby1:bby2] = data[indices, :, bbx1:bbx2, bby1:bby2]\n",
        "\n",
        "    # Adjust lambda to match the exact area ratio\n",
        "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (data.size()[-1] * data.size()[-2]))\n",
        "\n",
        "    # Store both labels and lambda\n",
        "    new_targets = [targets, shuffled_targets, lam]\n",
        "    return data, new_targets\n",
        "\n",
        "# Helper function to generate random bounding box\n",
        "def rand_bbox(size, lam):\n",
        "    W = size[2]  # Image width\n",
        "    H = size[3]  # Image height\n",
        "    cut_rat = np.sqrt(1. - lam)  # Cut ratio based on lambda\n",
        "    cut_w = int(W * cut_rat)     # Cut width\n",
        "    cut_h = int(H * cut_rat)     # Cut height\n",
        "\n",
        "    # Random center point for the cut\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "\n",
        "    # Bounding box coordinates, clipped to image boundaries\n",
        "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "\n",
        "    return bbx1, bby1, bbx2, bby2\n"
      ],
      "metadata": {
        "id": "Omjt1HcEMX4e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step-by-Step Explanation – CutMix Function**\n",
        "\n",
        "1. **Shuffle Batch Indices**  \n",
        "   - `torch.randperm(data.size(0))` creates a random permutation of batch indices.  \n",
        "   - This ensures images and labels are paired with different samples.\n",
        "\n",
        "2. **Get Shuffled Data & Labels**  \n",
        "   - `shuffled_data` = images from shuffled batch.  \n",
        "   - `shuffled_targets` = labels from shuffled batch.\n",
        "\n",
        "3. **Sample Mixing Factor**  \n",
        "   - `lam` is drawn from a Beta distribution.  \n",
        "   - Controls how much of each image is kept.\n",
        "\n",
        "4. **Generate Bounding Box**  \n",
        "   - Call `rand_bbox()` to get a random rectangular region to cut and replace.\n",
        "\n",
        "5. **Replace Image Patch**  \n",
        "   - In `data`, replace the selected patch with the corresponding patch from `shuffled_data`.\n",
        "\n",
        "6. **Adjust Lambda Value**  \n",
        "   - Recalculate `lam` based on **actual pixel area replaced** for accuracy.\n",
        "\n",
        "7. **Return Modified Data & Labels**  \n",
        "   - Output:  \n",
        "     - Modified `data` (images).  \n",
        "     - `new_targets` = `[original_labels, shuffled_labels, lam]`.\n"
      ],
      "metadata": {
        "id": "8C1auKwjMjeO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step-by-Step Explanation – rand_bbox Function**\n",
        "\n",
        "1. **Extract Image Dimensions**  \n",
        "   - `W` = image width, `H` = image height.\n",
        "\n",
        "2. **Compute Cut Ratio**  \n",
        "   - `cut_rat = sqrt(1 - lam)` determines the size of the cut.\n",
        "\n",
        "3. **Calculate Cut Dimensions**  \n",
        "   - `cut_w` = width of patch.  \n",
        "   - `cut_h` = height of patch.\n",
        "\n",
        "4. **Pick Random Center Point**  \n",
        "   - `(cx, cy)` = center coordinates of the cut patch.\n",
        "\n",
        "5. **Clip Coordinates to Image Bounds**  \n",
        "   - Ensure `(bbx1, bby1, bbx2, bby2)` stay within image dimensions.\n",
        "\n",
        "6. **Return Bounding Box Coordinates**  \n",
        "   - Output: `(bbx1, bby1, bbx2, bby2)`.\n"
      ],
      "metadata": {
        "id": "pguAMhf9MltW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The rest is the same as for Mixup:\n",
        "\n",
        "1.  Define a cutmix_criterion() functions to handle the custom loss (see the implementation of mixup_criterion())\n",
        "\n",
        "2.  Define a variable p_cutmix to control the portion of batches that will be augmented (see p_mixup)\n",
        "\n",
        "3.  Apply cutmix() and cutmix_criterion() in accordance to p_cutmix in the training code."
      ],
      "metadata": {
        "id": "w9zst9OXMrNO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Eu2ZVcvLeXq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}